# Configuration for Blind Navigation System

# Model Settings
model:
  weights: 'yolov5n.pt'  # Nano model for fast testing
  device: 'auto'         # 'auto' | 'cpu' | 'cuda' (set to 'cuda' on Jetson)
  confidence_threshold: 0.4  # Lowered to detect more objects
  iou_threshold: 0.45
  img_size: 640
  
# Camera Settings
camera:
  source: 0  # 0 for default webcam
  fps: 30
  width: 640
  height: 480
  horizontal_fov_deg: 60.0  # Typical webcam horizontal FOV
  vertical_fov_deg: 45.0    # Typical webcam vertical FOV

# Monocular depth model (optional - Depth‑Anything ONNX recommended)
depth:
  enabled: true                 # enable monocular depth estimation
  provider: 'onnx'              # 'onnx' (recommended) | 'midas' (fallback)
  model_path: 'models/depth_anything_small.onnx'
  input_size: 384               # model input size (square)
  run_every_n_frames: 2         # how often to run depth (for perf)
  auto_calibrate: true          # calibrate depth → meters using reference_class
  invert_depth: false           # set true if model outputs inverse depth
  output_scale: 1.0             # initial linear scale (meters = depth * scale)
  calibration:
    reference_class: 'person'
    reference_distance_m: 1.7

# Detection Settings
detection:
  # Priority obstacles for blind navigation
  priority_classes:
    - 'person'
    - 'bicycle'
    - 'car'
    - 'motorcycle'
    - 'bus'
    - 'truck'
    - 'traffic light'
    - 'stop sign'
    - 'bench'
    - 'chair'
    - 'potted plant'
    - 'dog'
    - 'cat'
    - 'laptop'
    - 'mouse'
    - 'keyboard'
    - 'cell phone'
    - 'book'
    - 'bottle'
    - 'cup'
  
  # Distance zones (based on bbox size)
  distance_zones:
    danger: 0.3   # Lowered for desktop testing
    warning: 0.15
    info: 0.0
  
  # Walking-path detection
  path_width_m: 0.6
  
  # Collision probability threshold
  collision_threshold: 0.4  # Lowered to see more alerts during testing

  # Close-person threshold (meters) — used to set `is_close` for 'person' detections
  close_distance_m: 1.5
  # If depth is unavailable, consider a person "close" when their bbox height
  # covers this fraction (0.0 - 1.0) of the frame height. Increase to make detection
  # less sensitive (default now 0.45).
  close_bbox_fraction: 0.45
  
# Audio Feedback Settings
audio:
  enabled: false
  engine: 'pyttsx3'
  rate: 180
  volume: 1.0
  priority_alert: true

# Voice Assistant Settings
voice:
  enabled: true  # Enable voice assistant

# Text-to-Speech provider options
tts:
  provider: 'auto'   # 'auto' | 'openai' | 'local'
  openai:
    model: 'gpt-4o-mini-tts'
    voice: 'alloy'
    format: 'wav'
  
# TensorRT Settings
tensorrt:
  enabled: false
  fp16: true
  workspace_size: 2

# Output Settings
output:
  display: true        # ENABLE for desktop
  save_video: false
  log_detections: true